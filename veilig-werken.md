# Veilig werken met AI

> *Privacy, grenzen en verantwoord gebruik.*

> üöß **Work in progress** ‚Äî Deze pagina wordt nog bijgeschaafd. Inhoud kan veranderen.

---

## De basisprincipes

Werken met AI en gevoelige gesprekken vraagt om bewuste keuzes. Niet omdat AI inherent onveilig is, maar omdat de drempels zo laag zijn dat het makkelijk is om te vergeten wat je deelt.

### 1. Weet waar je data naartoe gaat

**Cloud vs Lokaal:**
- Cloud-diensten (ChatGPT, Claude, Notion.ai) slaan data op servers
- Lokale tools (MacWhisper) verwerken alles op je eigen apparaat

**De keuze:**
| Situatie | Aanbeveling |
|----------|-------------|
| Gevoelige gesprekken (therapeutisch, personeels-issues) | Lokaal |
| Interne organisatie-zaken | Overwegen, check beleid |
| Openbare of minder gevoelige content | Cloud kan |
| Twijfel | Lokaal |

### 2. Vraag toestemming

**Bij opnemen:**
> "Ik neem dit gesprek op zodat we later terug kunnen kijken naar wat er gezegd is. De opname blijft bij mij en wordt alleen gebruikt voor [doel]. Is dat voor iedereen ok√©?"

Let op non-verbale signalen. Niet iedereen zegt hardop als ze oncomfortabel zijn.

**Bij delen met AI:**
Als je transcripten naar cloud-diensten stuurt, weten deelnemers dat? Expliciet maken is respectvol.

### 3. Anonimiseer waar nodig

**Wat te anonimiseren:**
- Namen van personen
- Identificerende details (functies, afdelingen, specifieke situaties)
- Alles wat naar individuen te herleiden is

**Wanneer:**
- Altijd bij gevoelige content
- Altijd bij delen buiten directe context
- Bij twijfel: anonimiseren

---

## De prompt-randvoorwaarden

Bij elke prompt voor gevoelige gesprekken, gebruik deze randvoorwaarden:

### Strikt op transcript

```
Baseer je strikt op wat er staat, geen verzinsels.
```

Dit voorkomt dat AI informatie toevoegt die er niet is.

### Bij twijfel benoemen

```
Bij twijfel: formuleer als "mogelijk" of "het lijkt alsof"
in plaats van stellige beweringen.
```

Dit voorkomt dat AI zekerheid simuleert die er niet is.

### Taal behouden

```
Gebruik de exacte woorden en formuleringen van deelnemers.
Geen parafrase naar professionele taal.
```

Dit voorkomt dat eigenaarschap verdwijnt door vertaling.

### AI markeren

```
Maak expliciet onderscheid tussen wat deelnemers zeiden
en wat AI observeert.
```

Dit voorkomt dat AI-interpretaties verward worden met wat er echt gezegd is.

---

## Checklist per sessie

### Voor de sessie

- [ ] Toestemming voor opname voorbereid
- [ ] Besloten: cloud of lokaal verwerken
- [ ] Duidelijkheid over wie toegang heeft tot output

### Na de sessie

- [ ] Transcript/opname veilig opgeslagen
- [ ] Anonimisatie waar nodig
- [ ] Deelnemers ge√Ønformeerd over wat er met hun input gebeurt

### Bij elke prompt

- [ ] "Strikt op transcript" instructie toegevoegd?
- [ ] "Bij twijfel: mogelijk" instructie toegevoegd?
- [ ] Taal-behoud instructie meegenomen?
- [ ] AI-output duidelijk als AI gemarkeerd?
- [ ] Privacy gecheckt voor de tool die je gebruikt?

---

## Tool-keuzes

| Tool               | Type                | Privacy-niveau                                  |
| ------------------ | ------------------- | ----------------------------------------------- |
| **MacWhisper**     | Lokale transcriptie | Hoog: alles blijft op je apparaat              |
| **Dembrane**       | Cloud + real-time   | Midden: check hun privacy-beleid               |
| **Notion.ai**      | Cloud transcriptie  | Lager: data op externe servers                 |
| **ChatGPT/Claude** | Cloud AI            | Lager: data kan gebruikt worden voor training* |
| **Lokale LLM's**   | Lokale AI           | Hoog: alles blijft lokaal                      |

*Check actuele voorwaarden, deze veranderen regelmatig.

---

## Wanneer niet met AI werken

Sommige gesprekken horen niet in een AI-verwerking, ook niet lokaal:

- **Crisisinterventies**: focus moet 100% op de mens zijn
- **Wanneer vertrouwelijkheid absoluut is**: sommige dingen horen alleen bij de mensen in de kamer
- **Wanneer je het gevoel hebt dat het niet past**: vertrouw dat gevoel

AI is een tool. Niet elke situatie vraagt om een tool.

---

## De ethische laag

### Eigenaarschap respecteren

Wanneer je output genereert op basis van andermans woorden, is die output niet van jou. Het is een bewerking van hun input.

**Implicatie:** Deel niet zomaar. Check of mensen zich herkennen. Vraag toestemming voor gebruik.

### Transparantie

Mensen hebben recht om te weten:
- Dat er opgenomen wordt
- Wat er met de opname gebeurt
- Dat AI betrokken is bij de verwerking
- Wat er met de output gedaan wordt

### Mens blijft eindverantwoordelijk

AI genereert, jij beslist. De output is een suggestie, geen conclusie.

**Implicatie:** Review wat AI maakt. Check of het klopt. Neem verantwoordelijkheid voor wat je deelt.

---

## De grenzen van AI

AI is krachtig maar heeft grenzen die relevant zijn voor veilig werken:

**AI kan stellig klinken maar het fout hebben:**
Een zekere toon is geen garantie voor waarheid. Controleer alles dat ertoe doet.

**AI mist wat niet in woorden gevangen werd:**
Het leest wat er staat, niet wat er hing: de blik, de zucht, de sfeer in de kamer.

**AI vindt vaak iets, de vraag is of het betekenisvol is:**
Niet alles wat AI ziet is een patroon. Controleer tegen je eigen ervaring.

**AI weegt ethiek niet automatisch af, en draagt de consequenties niet:**
Jij kent de mensen, jij staat in relatie met hen, jij bent degene die ze in de ogen kijkt. Die verantwoordelijkheid blijft bij jou.

---

## Samenvatting

**De kern:**
Weet waar je data naartoe gaat. Vraag toestemming. Anonimiseer waar nodig. Gebruik randvoorwaarden in je prompts. Markeer AI-output als AI. Blijf verantwoordelijk.

**De houding:**
AI als krachtige tool, niet als autoriteit. Mens blijft eindverantwoordelijk.

**De check:**
Bij twijfel, vraag jezelf: "Zou ik comfortabel zijn als de mensen in dit gesprek precies wisten wat ik hiermee doe?"

---

‚Üê [Terug naar het begin](waarom.md)

---

*"De drempels zijn laag. Dat maakt het makkelijk, en dat maakt het belangrijk om bewust te kiezen."*
